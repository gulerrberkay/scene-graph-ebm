2023-02-10 14:43:18,755 maskrcnn_benchmark INFO: Using 1 GPUs
2023-02-10 14:43:18,755 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_VGG16_1x.yaml', local_rank=0, skip_test=False, opts=['SOLVER.IMS_PER_BATCH', '1', 'TEST.IMS_PER_BATCH', '1', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '90000', 'SOLVER.STEPS', '(45000, 60000)', 'SOLVER.PRE_VAL', 'False'], distributed=False)
2023-02-10 14:43:18,756 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2023-02-10 14:43:22,457 maskrcnn_benchmark INFO: 
PyTorch version: 1.13.0+cu117
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Fedora Linux 37 (Thirty Seven) (x86_64)
GCC version: (conda-forge gcc 10.4.0-17) 10.4.0
Clang version: 15.0.7 (Fedora 15.0.7-1.fc37)
CMake version: version 3.25.2
Libc version: glibc-2.36

Python version: 3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-6.1.9-200.fc37.x86_64-x86_64-with-glibc2.36
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce GTX 1650
Nvidia driver version: 525.85.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] numpy==1.23.5
[pip3] torch==1.13.0
[pip3] torch-scatter==2.1.0
[pip3] torchaudio==0.13.0
[pip3] torchvision==0.14.0
[conda] numpy                     1.23.5                   pypi_0    pypi
[conda] torch                     1.13.0                   pypi_0    pypi
[conda] torch-scatter             2.1.0                    pypi_0    pypi
[conda] torchaudio                0.13.0                   pypi_0    pypi
[conda] torchvision               0.14.0                   pypi_0    pypi
        Pillow (9.3.0)
2023-02-10 14:43:22,457 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_VGG16_1x.yaml
2023-02-10 14:43:22,457 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/MSRA/R-101"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 512
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: False
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (16, )
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 512
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 64
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.0625, )
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 2048
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 64
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512
    POOLING_ALL_LEVELS: True
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #PREDICTOR: "MotifPredictor"
    PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "CausalAnalysisPredictor"
    #PREDICTOR: "TransformerPredictor"
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    # Parameter for Transformer Module
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048 
DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (90000, 120000)
  MAX_ITER: 180000
  VAL_PERIOD: 1000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 5000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.5
    MAX_DECAY_STEP: 5
OUTPUT_DIR: './output/relation_baseline'
TEST:
  RELATION:
    REQUIRE_OVERLAP: True
    LATER_NMS_PREDICTION_THRES: 0.5

2023-02-10 14:43:22,458 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  NUM_OBJ_CLASSES: -1
  NUM_REL_CLASSES: -1
  TEST: ('VG_stanford_filtered_with_attribute_test',)
  TRAIN: ('VG_stanford_filtered_with_attribute_train',)
  VAL: ('VG_stanford_filtered_with_attribute_val',)
DTYPE: float16
ENERGY_MODEL:
  DATA_NOISE_VAR: 0.0001
  L2COEFF: 1
  LOSS: ContrastiveDivergence
  META_ARCHITECTURE: GraphEnergyModel
  TEMP: 1
  TRAINIG_MODE: joint
GLOVE_DIR: /users/students/r0879687/amager/vg/glove
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [123.68, 116.779, 103.939]
  PIXEL_STD: [58.393, 57.12, 57.375]
  SATURATION: 0.0
  TO_BGR255: False
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  BASE_ONLY: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DEV_RUN: False
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PRETRAINED_DETECTOR_CKPT: 
  RELATION_ON: True
  RESNETS:
    BACKBONE_OUT_CHANNELS: 512
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 201
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 2048
    NUM_CLASSES: 151
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 64
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: False
    BATCH_SIZE_PER_IMAGE: 64
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: False
      EFFECT_TYPE: none
      FUSION_TYPE: sum
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: False
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EBM:
      OBJ_EMBED_DIM: 512
      OBJ_LABEL_EMBED_DIM: 512
      POOLING_DIM: 512
      REL_EMBED_DIM: 512
      REL_LABEL_EMBED_DIM: 512
    EMBED_DIM: 200
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    LABEL_SMOOTHING_LOSS: False
    NUM_CLASSES: 51
    NUM_SAMPLE_PER_GT_REL: 4
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: VCTreePredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REQUIRE_BOX_OVERLAP: True
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 512
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/MSRA/R-101
OUTPUT_DIR: ./output/relation_baseline
PATHS_CATALOG: /users/students/r0879687/Documents/Master_thesis/ebm/energy-based-scene-graph/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /users/students/r0879687/amager/vg/VG_100K
SAMPLER:
  GRAD_CLIP: 0.01
  ITERS: 10
  LR: 0.1
  NAME: SGLD
  VAR: 0.001
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 2000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 1
  MAX_ITER: 90000
  MOMENTUM: 0.9
  PRE_VAL: False
  PRINT_GRAD_FREQ: 5000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.5
    MAX_DECAY_STEP: 5
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (45000, 60000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 1000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: True
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: True
    SYNC_GATHER: False
  SAVE_PROPOSALS: False
WANDB:
  MUTE: False
2023-02-10 14:43:22,459 maskrcnn_benchmark INFO: Saving config into: ./output/relation_baseline/config.yml
2023-02-10 14:43:22,484 maskrcnn_benchmark INFO: #################### prepare training ####################
2023-02-10 14:43:22,486 maskrcnn_benchmark.modeling.detector.generalized_rcnn INFO: #################### Building Backbone ####################
2023-02-10 14:43:23,384 maskrcnn_benchmark.modeling.detector.generalized_rcnn INFO: #################### Building RPN ####################
2023-02-10 14:43:23,450 maskrcnn_benchmark.modeling.detector.generalized_rcnn INFO: #################### Building ROI Heads ####################
2023-02-10 14:43:26,142 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-02-10 14:43:26,143 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2023-02-10 14:47:18,208 maskrcnn_benchmark.data.build INFO: finish
2023-02-10 14:47:18,208 maskrcnn_benchmark.data.build INFO: Save data statistics to: ./output/relation_baseline/VG_stanford_filtered_with_attribute_train_statistics.cache
2023-02-10 14:47:18,209 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-02-10 14:47:41,698 maskrcnn_benchmark INFO: #################### end model construction ####################
2023-02-10 14:47:41,992 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2023-02-10 14:47:42,002 maskrcnn_benchmark INFO: #################### end distributed ####################
2023-02-10 14:47:42,004 maskrcnn_benchmark.utils.checkpoint INFO: No checkpoint found. Initializing model from scratch
2023-02-10 14:47:42,004 maskrcnn_benchmark INFO: #################### end load checkpointer ####################
2023-02-10 14:49:21,872 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into ./output/relation_baseline/labels.json
2023-02-10 14:49:23,666 maskrcnn_benchmark INFO: #################### end dataloader ####################
2023-02-10 14:49:23,667 maskrcnn_benchmark INFO: Start training
2023-02-23 23:40:46,183 maskrcnn_benchmark INFO: Using 1 GPUs
2023-02-23 23:40:46,184 maskrcnn_benchmark INFO: Namespace(config_file='', local_rank=0, skip_test=False, opts=[], distributed=False)
2023-02-23 23:40:46,184 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2023-02-23 23:40:49,936 maskrcnn_benchmark INFO: 
PyTorch version: 1.13.0+cu117
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Fedora Linux 37 (KDE Plasma) (x86_64)
GCC version: (GCC) 12.2.1 20221121 (Red Hat 12.2.1-4)
Clang version: 15.0.7 (Fedora 15.0.7-1.fc37)
CMake version: version 3.26.0-rc3
Libc version: glibc-2.36

Python version: 3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-6.1.11-200.fc37.x86_64-x86_64-with-glibc2.36
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce GTX 960
Nvidia driver version: 525.89.02
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] numpy==1.23.5
[pip3] torch==1.13.0
[pip3] torch-scatter==2.1.0
[pip3] torchaudio==0.13.0
[pip3] torchvision==0.14.0
[conda] Could not collect
        Pillow (9.3.0)
2023-02-23 23:40:49,937 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml
2023-02-23 23:40:49,938 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  #WEIGHT: "catalog://ImageNetPretrained/20171220/X-101-32x8d"
  PRETRAINED_DETECTOR_CKPT: "/users/students/r0879687/amager/vg/pretrained-detector/pretrained_faster_rcnn/model_final.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #################### Select Relationship Model ####################
    PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    #PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048
    ############### Parameters for Energy Model ##############
    EBM:
      OBJ_EMBED_DIM: 512
      REL_EMBED_DIM: 512
      OBJ_LABEL_EMBED_DIM: 512
      REL_LABEL_EMBED_DIM: 512
      POOLING_DIM: 512
DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5

2023-02-23 23:40:49,940 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  NUM_OBJ_CLASSES: -1
  NUM_REL_CLASSES: -1
  TEST: ('VG_stanford_filtered_with_attribute_test',)
  TRAIN: ('VG_stanford_filtered_with_attribute_train',)
  VAL: ('VG_stanford_filtered_with_attribute_val',)
DTYPE: float32
ENERGY_MODEL:
  DATA_NOISE_VAR: 0.0001
  L2COEFF: 1
  LOSS: ContrastiveDivergence
  META_ARCHITECTURE: GraphEnergyModel
  TEMP: 1
  TRAINIG_MODE: joint
GLOVE_DIR: /users/students/r0879687/amager/vg/glove
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  FLIP_PROB_TRAIN: 0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  BASE_ONLY: True
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DEV_RUN: False
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PRETRAINED_DETECTOR_CKPT: /users/students/r0879687/amager/vg/pretrained-detector/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 201
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 151
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: none
      FUSION_TYPE: sum
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EBM:
      OBJ_EMBED_DIM: 512
      OBJ_LABEL_EMBED_DIM: 512
      POOLING_DIM: 512
      REL_EMBED_DIM: 512
      REL_LABEL_EMBED_DIM: 512
    EMBED_DIM: 200
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    LABEL_SMOOTHING_LOSS: False
    NUM_CLASSES: 51
    NUM_SAMPLE_PER_GT_REL: 4
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: ./output/relation_baseline
PATHS_CATALOG: /users/students/r0879687/Documents/Master_thesis/ebm/energy-based-scene-graph/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /users/students/r0879687/amager/vg/VG_100K
SAMPLER:
  GRAD_CLIP: 0.01
  ITERS: 10
  LR: 0.1
  NAME: SGLD
  VAR: 0.001
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 2000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 1
  MAX_ITER: 40000
  MOMENTUM: 0.9
  PRE_VAL: True
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 2000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
WANDB:
  MUTE: False
2023-02-23 23:40:49,941 maskrcnn_benchmark INFO: Saving config into: ./output/relation_baseline/config.yml
2023-02-23 23:40:50,046 maskrcnn_benchmark INFO: #################### prepare training ####################
2023-02-23 23:40:50,049 maskrcnn_benchmark.modeling.detector.generalized_rcnn INFO: #################### Building Backbone ####################
2023-02-23 23:40:52,023 maskrcnn_benchmark.modeling.detector.generalized_rcnn INFO: #################### Building RPN ####################
2023-02-23 23:40:52,047 maskrcnn_benchmark.modeling.detector.generalized_rcnn INFO: #################### Building ROI Heads ####################
2023-02-23 23:40:57,759 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-02-23 23:40:57,759 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2023-02-23 23:40:57,916 maskrcnn_benchmark.data.build INFO: Loading data statistics from: ./output/relation_baseline/VG_stanford_filtered_with_attribute_train_statistics.cache
2023-02-23 23:40:57,917 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-02-23 23:42:31,768 maskrcnn_benchmark INFO: #################### end model construction ####################
2023-02-23 23:43:21,968 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2023-02-23 23:43:21,969 maskrcnn_benchmark INFO: #################### end distributed ####################
2023-02-23 23:43:21,973 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from /users/students/r0879687/amager/vg/pretrained-detector/pretrained_faster_rcnn/model_final.pth
2023-02-23 23:45:10,620 maskrcnn_benchmark INFO: #################### end load checkpointer ####################
2023-02-23 23:47:51,531 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into ./output/relation_baseline/labels.json
2023-02-23 23:48:44,450 maskrcnn_benchmark INFO: #################### end dataloader ####################
2023-02-23 23:48:44,450 maskrcnn_benchmark INFO: Validate before training
2023-02-23 23:48:44,455 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2023-02-24 00:31:53,288 maskrcnn_benchmark INFO: Total run time: 0:43:08.803045 (0.5177606090545654 s / img per device, on 1 devices)
2023-02-24 00:31:53,290 maskrcnn_benchmark INFO: Model inference time: 0:40:21.993651 (0.4843987302303314 s / img per device, on 1 devices)
2023-02-24 00:39:02,776 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.4605;   R @ 50: 0.5556;   R @ 100: 0.5954;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.5078; ngR @ 50: 0.6525; ngR @ 100: 0.7463;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0000;  zR @ 50: 0.0000;  zR @ 100: 0.0000;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  zR @ 20: 0.0247;  zR @ 50: 0.0558;  zR @ 100: 0.0876;  for mode=predcls, type=1 Shot Recall.
 zR @ 20: 0.0270;  zR @ 50: 0.0806;  zR @ 100: 0.1076;  for mode=predcls, type=2 Shot Recall.
 zR @ 20: 0.0147;  zR @ 50: 0.0769;  zR @ 100: 0.1502;  for mode=predcls, type=3 Shot Recall.
 zR @ 20: 0.0622;  zR @ 50: 0.1481;  zR @ 100: 0.2124;  for mode=predcls, type=4 Shot Recall.
 zR @ 20: 0.0811;  zR @ 50: 0.1784;  zR @ 100: 0.2351;  for mode=predcls, type=5 Shot Recall.
 zR @ 20: 0.1171;  zR @ 50: 0.2034;  zR @ 100: 0.2504;  for mode=predcls, type=6 Shot Recall.
 zR @ 20: 0.0951;  zR @ 50: 0.1605;  zR @ 100: 0.2139;  for mode=predcls, type=7 Shot Recall.
 zR @ 20: 0.0985;  zR @ 50: 0.1667;  zR @ 100: 0.2015;  for mode=predcls, type=8 Shot Recall.
 zR @ 20: 0.1939;  zR @ 50: 0.3209;  zR @ 100: 0.3561;  for mode=predcls, type=9 Shot Recall.
 zR @ 20: 0.1261;  zR @ 50: 0.2196;  zR @ 100: 0.3074;  for mode=predcls, type=10 Shot Recall.
 zR @ 20: 0.1170;  zR @ 50: 0.1809;  zR @ 100: 0.2565;  for mode=predcls, type=20 Shot Recall.
 zR @ 20: 0.1214;  zR @ 50: 0.2071;  zR @ 100: 0.2964;  for mode=predcls, type=25 Shot Recall.
 zR @ 20: 0.0779;  zR @ 50: 0.1299;  zR @ 100: 0.1688;  for mode=predcls, type=30 Shot Recall.
 zR @ 20: 0.3547;  zR @ 50: 0.4360;  zR @ 100: 0.4884;  for mode=predcls, type=40 Shot Recall.
 zR @ 20: 0.1986;  zR @ 50: 0.3042;  zR @ 100: 0.4115;  for mode=predcls, type=50 Shot Recall.
 zR @ 20: 0.3846;  zR @ 50: 0.5385;  zR @ 100: 0.5769;  for mode=predcls, type=100 Shot Recall.
 zR @ 20: 1.0000;  zR @ 50: 1.0000;  zR @ 100: 1.0000;  for mode=predcls, type=200 Shot Recall.
SGG eval:  mR @ 20: 0.0798;  mR @ 50: 0.1256;  mR @ 100: 0.1486;  for mode=predcls, type=Mean Recall.
(above:0.0399) (across:0.0000) (against:0.0000) (along:0.0769) (and:0.0000) (at:0.1485) (attached to:0.0046) (behind:0.3922) (belonging to:0.0000) (between:0.0000) (carrying:0.4342) (covered in:0.1429) (covering:0.0286) (eating:0.7381) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0074) (has:0.6921) (holding:0.3690) (in:0.3163) (in front of:0.0720) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.2844) (of:0.3961) (on:0.8176) (on back of:0.0455) (over:0.0325) (painted on:0.0000) (parked on:0.0040) (part of:0.0000) (playing:0.0000) (riding:0.5848) (says:0.0000) (sitting on:0.3124) (standing on:0.0000) (to:0.0278) (under:0.1293) (using:0.2115) (walking in:0.0000) (walking on:0.0074) (watching:0.0882) (wearing:0.9159) (wears:0.0000) (with:0.0722) 
SGG eval:   A @ 20: 0.6418;   A @ 50: 0.6467;   A @ 100: 0.6467;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2023-02-24 00:39:03,907 maskrcnn_benchmark INFO: Start training
2023-02-24 00:39:21,227 maskrcnn_benchmark INFO: ---Total norm 0.00000 clip coef 5000000.00000-----------------
2023-02-24 00:39:21,232 maskrcnn_benchmark INFO: -------------------------------
2023-02-24 00:40:56,829 maskrcnn_benchmark INFO: eta: 6:10:14  iter: 200  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4375 (0.5581)  data: 0.0041 (0.0169)  lr: 0.004582  max mem: 3144
2023-02-24 00:42:30,834 maskrcnn_benchmark INFO: eta: 5:41:25  iter: 400  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4718 (0.5173)  data: 0.0042 (0.0138)  lr: 0.008182  max mem: 3144
2023-02-24 00:44:07,525 maskrcnn_benchmark INFO: eta: 5:32:17  iter: 600  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4714 (0.5060)  data: 0.0041 (0.0106)  lr: 0.010000  max mem: 3144
2023-02-24 00:45:42,546 maskrcnn_benchmark INFO: eta: 5:25:33  iter: 800  loss: 853.6354 (nan)  loss_rel: 849.6068 (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4491 (0.4983)  data: 0.0041 (0.0090)  lr: 0.010000  max mem: 3144
2023-02-24 00:47:18,255 maskrcnn_benchmark INFO: eta: 5:21:19  iter: 1000  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4605 (0.4943)  data: 0.0042 (0.0080)  lr: 0.010000  max mem: 3144
2023-02-24 00:48:54,058 maskrcnn_benchmark INFO: eta: 5:18:01  iter: 1200  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4647 (0.4918)  data: 0.0043 (0.0074)  lr: 0.010000  max mem: 3144
2023-02-24 00:50:29,152 maskrcnn_benchmark INFO: eta: 5:14:53  iter: 1400  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4560 (0.4895)  data: 0.0042 (0.0070)  lr: 0.010000  max mem: 3144
2023-02-24 00:52:05,969 maskrcnn_benchmark INFO: eta: 5:12:49  iter: 1600  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.5041 (0.4888)  data: 0.0042 (0.0067)  lr: 0.010000  max mem: 3144
2023-02-24 00:53:41,591 maskrcnn_benchmark INFO: eta: 5:10:26  iter: 1800  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4727 (0.4876)  data: 0.0041 (0.0064)  lr: 0.010000  max mem: 3144
2023-02-24 00:55:16,020 maskrcnn_benchmark INFO: eta: 5:07:50  iter: 2000  loss: 614.7601 (nan)  loss_rel: 610.7315 (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4593 (0.4861)  data: 0.0042 (0.0062)  lr: 0.010000  max mem: 3144
2023-02-24 00:55:16,029 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./output/relation_baseline/model_0002000.pth
2023-02-24 00:55:43,457 maskrcnn_benchmark INFO: Start validating
2023-02-24 00:55:43,769 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2023-02-24 01:37:44,656 maskrcnn_benchmark INFO: Total run time: 0:42:00.885638 (0.5041771276473999 s / img per device, on 1 devices)
2023-02-24 01:37:44,659 maskrcnn_benchmark INFO: Model inference time: 0:39:29.706278 (0.473941255569458 s / img per device, on 1 devices)
2023-02-24 01:44:18,309 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2069;   R @ 50: 0.2754;   R @ 100: 0.3174;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.2445; ngR @ 50: 0.3664; ngR @ 100: 0.4682;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0000;  zR @ 50: 0.0000;  zR @ 100: 0.0044;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  zR @ 20: 0.0215;  zR @ 50: 0.0379;  zR @ 100: 0.0432;  for mode=predcls, type=1 Shot Recall.
 zR @ 20: 0.0335;  zR @ 50: 0.0495;  zR @ 100: 0.0586;  for mode=predcls, type=2 Shot Recall.
 zR @ 20: 0.0289;  zR @ 50: 0.0628;  zR @ 100: 0.0980;  for mode=predcls, type=3 Shot Recall.
 zR @ 20: 0.0601;  zR @ 50: 0.0966;  zR @ 100: 0.1330;  for mode=predcls, type=4 Shot Recall.
 zR @ 20: 0.0875;  zR @ 50: 0.1281;  zR @ 100: 0.1489;  for mode=predcls, type=5 Shot Recall.
 zR @ 20: 0.0436;  zR @ 50: 0.0855;  zR @ 100: 0.1188;  for mode=predcls, type=6 Shot Recall.
 zR @ 20: 0.0475;  zR @ 50: 0.0960;  zR @ 100: 0.1130;  for mode=predcls, type=7 Shot Recall.
 zR @ 20: 0.0492;  zR @ 50: 0.0876;  zR @ 100: 0.1118;  for mode=predcls, type=8 Shot Recall.
 zR @ 20: 0.1216;  zR @ 50: 0.1701;  zR @ 100: 0.1905;  for mode=predcls, type=9 Shot Recall.
 zR @ 20: 0.0631;  zR @ 50: 0.0914;  zR @ 100: 0.1016;  for mode=predcls, type=10 Shot Recall.
 zR @ 20: 0.0646;  zR @ 50: 0.1469;  zR @ 100: 0.1948;  for mode=predcls, type=20 Shot Recall.
 zR @ 20: 0.1200;  zR @ 50: 0.1714;  zR @ 100: 0.2298;  for mode=predcls, type=25 Shot Recall.
 zR @ 20: 0.1039;  zR @ 50: 0.1775;  zR @ 100: 0.2294;  for mode=predcls, type=30 Shot Recall.
 zR @ 20: 0.1628;  zR @ 50: 0.1977;  zR @ 100: 0.2500;  for mode=predcls, type=40 Shot Recall.
 zR @ 20: 0.1528;  zR @ 50: 0.2778;  zR @ 100: 0.3403;  for mode=predcls, type=50 Shot Recall.
 zR @ 20: 0.2179;  zR @ 50: 0.3462;  zR @ 100: 0.3846;  for mode=predcls, type=100 Shot Recall.
 zR @ 20: 0.6667;  zR @ 50: 0.6667;  zR @ 100: 0.6667;  for mode=predcls, type=200 Shot Recall.
SGG eval:  mR @ 20: 0.0644;  mR @ 50: 0.1018;  mR @ 100: 0.1263;  for mode=predcls, type=Mean Recall.
(above:0.1033) (across:0.0000) (against:0.0263) (along:0.1987) (and:0.0000) (at:0.2392) (attached to:0.0301) (behind:0.1653) (belonging to:0.0000) (between:0.0577) (carrying:0.1096) (covered in:0.1667) (covering:0.0898) (eating:0.3810) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0333) (hanging from:0.0147) (has:0.2908) (holding:0.2236) (in:0.3878) (in front of:0.0395) (laying on:0.0476) (looking at:0.0000) (lying on:0.0000) (made of:0.1429) (mounted on:0.0435) (near:0.0591) (of:0.4278) (on:0.3524) (on back of:0.0455) (over:0.0325) (painted on:0.1429) (parked on:0.4070) (part of:0.0000) (playing:0.0000) (riding:0.3393) (says:0.0000) (sitting on:0.2438) (standing on:0.0272) (to:0.1667) (under:0.0748) (using:0.0962) (walking in:0.0769) (walking on:0.1348) (watching:0.0588) (wearing:0.5750) (wears:0.0711) (with:0.1940) 
SGG eval:   A @ 20: 0.3412;   A @ 50: 0.3437;   A @ 100: 0.3437;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2023-02-24 01:44:20,621 maskrcnn_benchmark INFO: Validation Result: 0.3174
2023-02-24 01:46:02,698 maskrcnn_benchmark INFO: eta: 19:10:37  iter: 2200  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4790 (1.8264)  data: 0.0043 (1.3445)  lr: 0.010000  max mem: 3144
2023-02-24 01:47:38,687 maskrcnn_benchmark INFO: eta: 17:54:24  iter: 2400  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4750 (1.7145)  data: 0.0042 (1.2331)  lr: 0.010000  max mem: 3144
2023-02-24 01:49:16,656 maskrcnn_benchmark INFO: eta: 16:49:58  iter: 2600  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4726 (1.6203)  data: 0.0042 (1.1386)  lr: 0.010000  max mem: 3144
2023-02-24 01:50:50,360 maskrcnn_benchmark INFO: eta: 15:53:34  iter: 2800  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4495 (1.5380)  data: 0.0041 (1.0576)  lr: 0.010000  max mem: 3144
2023-02-24 01:52:25,433 maskrcnn_benchmark INFO: eta: 15:04:45  iter: 3000  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4722 (1.4672)  data: 0.0041 (0.9874)  lr: 0.010000  max mem: 3144
2023-02-24 01:54:00,450 maskrcnn_benchmark INFO: eta: 14:21:50  iter: 3200  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4651 (1.4052)  data: 0.0042 (0.9259)  lr: 0.010000  max mem: 3144
2023-02-24 01:55:34,369 maskrcnn_benchmark INFO: eta: 13:43:34  iter: 3400  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4608 (1.3501)  data: 0.0040 (0.8717)  lr: 0.010000  max mem: 3144
2023-02-24 01:57:12,689 maskrcnn_benchmark INFO: eta: 13:10:08  iter: 3600  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4688 (1.3024)  data: 0.0044 (0.8235)  lr: 0.010000  max mem: 3144
2023-02-24 01:58:47,001 maskrcnn_benchmark INFO: eta: 12:39:25  iter: 3800  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4661 (1.2587)  data: 0.0041 (0.7804)  lr: 0.010000  max mem: 3144
2023-02-24 02:00:22,421 maskrcnn_benchmark INFO: ---Total norm 0.00000 clip coef 5000000.00000-----------------
2023-02-24 02:00:22,422 maskrcnn_benchmark INFO: -------------------------------
2023-02-24 02:00:22,423 maskrcnn_benchmark INFO: eta: 12:11:46  iter: 4000  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4648 (1.2196)  data: 0.0042 (0.7416)  lr: 0.010000  max mem: 3144
2023-02-24 02:00:22,428 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./output/relation_baseline/model_0004000.pth
2023-02-24 02:00:51,048 maskrcnn_benchmark INFO: Start validating
2023-02-24 02:00:51,361 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2023-02-24 02:42:31,492 maskrcnn_benchmark INFO: Total run time: 0:41:40.129712 (0.5000259424209594 s / img per device, on 1 devices)
2023-02-24 02:42:31,494 maskrcnn_benchmark INFO: Model inference time: 0:39:19.894294 (0.47197885880470275 s / img per device, on 1 devices)
2023-02-24 02:49:03,678 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.1991;   R @ 50: 0.2660;   R @ 100: 0.3061;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.2394; ngR @ 50: 0.3577; ngR @ 100: 0.4541;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0000;  zR @ 50: 0.0133;  zR @ 100: 0.0133;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  zR @ 20: 0.0229;  zR @ 50: 0.0430;  zR @ 100: 0.0560;  for mode=predcls, type=1 Shot Recall.
 zR @ 20: 0.0345;  zR @ 50: 0.0450;  zR @ 100: 0.0571;  for mode=predcls, type=2 Shot Recall.
 zR @ 20: 0.0345;  zR @ 50: 0.0682;  zR @ 100: 0.1015;  for mode=predcls, type=3 Shot Recall.
 zR @ 20: 0.0599;  zR @ 50: 0.0964;  zR @ 100: 0.1335;  for mode=predcls, type=4 Shot Recall.
 zR @ 20: 0.0619;  zR @ 50: 0.0992;  zR @ 100: 0.1247;  for mode=predcls, type=5 Shot Recall.
 zR @ 20: 0.0795;  zR @ 50: 0.1060;  zR @ 100: 0.1308;  for mode=predcls, type=6 Shot Recall.
 zR @ 20: 0.0716;  zR @ 50: 0.1056;  zR @ 100: 0.1241;  for mode=predcls, type=7 Shot Recall.
 zR @ 20: 0.0862;  zR @ 50: 0.1146;  zR @ 100: 0.1279;  for mode=predcls, type=8 Shot Recall.
 zR @ 20: 0.1036;  zR @ 50: 0.1342;  zR @ 100: 0.1915;  for mode=predcls, type=9 Shot Recall.
 zR @ 20: 0.0649;  zR @ 50: 0.1110;  zR @ 100: 0.1306;  for mode=predcls, type=10 Shot Recall.
 zR @ 20: 0.1497;  zR @ 50: 0.1816;  zR @ 100: 0.2242;  for mode=predcls, type=20 Shot Recall.
 zR @ 20: 0.1201;  zR @ 50: 0.1856;  zR @ 100: 0.2201;  for mode=predcls, type=25 Shot Recall.
 zR @ 20: 0.0779;  zR @ 50: 0.1169;  zR @ 100: 0.1429;  for mode=predcls, type=30 Shot Recall.
 zR @ 20: 0.1337;  zR @ 50: 0.2248;  zR @ 100: 0.2713;  for mode=predcls, type=40 Shot Recall.
 zR @ 20: 0.1111;  zR @ 50: 0.1597;  zR @ 100: 0.1806;  for mode=predcls, type=50 Shot Recall.
 zR @ 20: 0.3654;  zR @ 50: 0.3654;  zR @ 100: 0.3654;  for mode=predcls, type=100 Shot Recall.
 zR @ 20: 0.3333;  zR @ 50: 0.6667;  zR @ 100: 0.6667;  for mode=predcls, type=200 Shot Recall.
SGG eval:  mR @ 20: 0.0623;  mR @ 50: 0.0904;  mR @ 100: 0.1123;  for mode=predcls, type=Mean Recall.
(above:0.0987) (across:0.0000) (against:0.0000) (along:0.1538) (and:0.0000) (at:0.1710) (attached to:0.0594) (behind:0.1758) (belonging to:0.0000) (between:0.0000) (carrying:0.1404) (covered in:0.0714) (covering:0.1265) (eating:0.1429) (flying in:0.0000) (for:0.0185) (from:0.0000) (growing on:0.1000) (hanging from:0.0000) (has:0.2958) (holding:0.1634) (in:0.3808) (in front of:0.0256) (laying on:0.0476) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0659) (of:0.4081) (on:0.3442) (on back of:0.0000) (over:0.0488) (painted on:0.1429) (parked on:0.3885) (part of:0.0000) (playing:0.0000) (riding:0.3006) (says:0.0000) (sitting on:0.2086) (standing on:0.0373) (to:0.1667) (under:0.0731) (using:0.0769) (walking in:0.0769) (walking on:0.1708) (watching:0.1176) (wearing:0.5505) (wears:0.0610) (with:0.2040) 
SGG eval:   A @ 20: 0.3421;   A @ 50: 0.3448;   A @ 100: 0.3448;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2023-02-24 02:49:04,266 maskrcnn_benchmark INFO: Validation Result: 0.3061
2023-02-24 02:50:40,845 maskrcnn_benchmark INFO: eta: 18:41:45  iter: 4200  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4451 (1.8800)  data: 0.0043 (1.4022)  lr: 0.010000  max mem: 3144
2023-02-24 02:52:14,759 maskrcnn_benchmark INFO: eta: 17:57:33  iter: 4400  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4529 (1.8161)  data: 0.0041 (1.3388)  lr: 0.010000  max mem: 3144
2023-02-24 02:53:49,394 maskrcnn_benchmark INFO: eta: 17:17:03  iter: 4600  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4701 (1.7577)  data: 0.0042 (1.2808)  lr: 0.010000  max mem: 3144
2023-02-24 02:55:25,762 maskrcnn_benchmark INFO: eta: 16:40:00  iter: 4800  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4691 (1.7046)  data: 0.0041 (1.2276)  lr: 0.010000  max mem: 3144
2023-02-24 02:56:59,792 maskrcnn_benchmark INFO: eta: 16:05:31  iter: 5000  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4548 (1.6552)  data: 0.0042 (1.1787)  lr: 0.010000  max mem: 3144
2023-02-24 02:58:33,818 maskrcnn_benchmark INFO: eta: 15:33:33  iter: 5200  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4705 (1.6096)  data: 0.0042 (1.1335)  lr: 0.010000  max mem: 3144
2023-02-24 03:00:08,295 maskrcnn_benchmark INFO: eta: 15:03:54  iter: 5400  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4585 (1.5675)  data: 0.0041 (1.0917)  lr: 0.010000  max mem: 3144
2023-02-24 03:01:44,749 maskrcnn_benchmark INFO: eta: 14:36:27  iter: 5600  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.5045 (1.5287)  data: 0.0042 (1.0528)  lr: 0.010000  max mem: 3144
2023-02-24 03:03:18,806 maskrcnn_benchmark INFO: eta: 14:10:34  iter: 5800  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4571 (1.4922)  data: 0.0041 (1.0167)  lr: 0.010000  max mem: 3144
2023-02-24 03:05:07,436 maskrcnn_benchmark INFO: eta: 13:47:39  iter: 6000  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4597 (1.4606)  data: 0.0042 (0.9829)  lr: 0.010000  max mem: 3144
2023-02-24 03:05:07,442 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./output/relation_baseline/model_0006000.pth
2023-02-24 03:05:32,265 maskrcnn_benchmark INFO: Start validating
2023-02-24 03:05:32,624 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2023-02-24 03:46:52,775 maskrcnn_benchmark INFO: Total run time: 0:41:20.149948 (0.496029989528656 s / img per device, on 1 devices)
2023-02-24 03:46:52,777 maskrcnn_benchmark INFO: Model inference time: 0:39:21.070243 (0.47221404857635496 s / img per device, on 1 devices)
2023-02-24 03:53:24,677 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2032;   R @ 50: 0.2677;   R @ 100: 0.3063;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.2414; ngR @ 50: 0.3569; ngR @ 100: 0.4541;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0000;  zR @ 50: 0.0044;  zR @ 100: 0.0089;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  zR @ 20: 0.0208;  zR @ 50: 0.0361;  zR @ 100: 0.0541;  for mode=predcls, type=1 Shot Recall.
 zR @ 20: 0.0285;  zR @ 50: 0.0450;  zR @ 100: 0.0551;  for mode=predcls, type=2 Shot Recall.
 zR @ 20: 0.0302;  zR @ 50: 0.0660;  zR @ 100: 0.0935;  for mode=predcls, type=3 Shot Recall.
 zR @ 20: 0.0504;  zR @ 50: 0.0848;  zR @ 100: 0.1271;  for mode=predcls, type=4 Shot Recall.
 zR @ 20: 0.0461;  zR @ 50: 0.0987;  zR @ 100: 0.1189;  for mode=predcls, type=5 Shot Recall.
 zR @ 20: 0.0470;  zR @ 50: 0.1026;  zR @ 100: 0.1256;  for mode=predcls, type=6 Shot Recall.
 zR @ 20: 0.0488;  zR @ 50: 0.0799;  zR @ 100: 0.0897;  for mode=predcls, type=7 Shot Recall.
 zR @ 20: 0.0677;  zR @ 50: 0.1121;  zR @ 100: 0.1520;  for mode=predcls, type=8 Shot Recall.
 zR @ 20: 0.1201;  zR @ 50: 0.2065;  zR @ 100: 0.2569;  for mode=predcls, type=9 Shot Recall.
 zR @ 20: 0.0450;  zR @ 50: 0.0712;  zR @ 100: 0.1136;  for mode=predcls, type=10 Shot Recall.
 zR @ 20: 0.1182;  zR @ 50: 0.1551;  zR @ 100: 0.1924;  for mode=predcls, type=20 Shot Recall.
 zR @ 20: 0.1440;  zR @ 50: 0.1851;  zR @ 100: 0.2130;  for mode=predcls, type=25 Shot Recall.
 zR @ 20: 0.1039;  zR @ 50: 0.1299;  zR @ 100: 0.1818;  for mode=predcls, type=30 Shot Recall.
 zR @ 20: 0.1628;  zR @ 50: 0.1919;  zR @ 100: 0.2209;  for mode=predcls, type=40 Shot Recall.
 zR @ 20: 0.1111;  zR @ 50: 0.1944;  zR @ 100: 0.2569;  for mode=predcls, type=50 Shot Recall.
 zR @ 20: 0.3077;  zR @ 50: 0.4231;  zR @ 100: 0.4231;  for mode=predcls, type=100 Shot Recall.
 zR @ 20: 0.6667;  zR @ 50: 0.6667;  zR @ 100: 0.6667;  for mode=predcls, type=200 Shot Recall.
SGG eval:  mR @ 20: 0.0670;  mR @ 50: 0.1035;  mR @ 100: 0.1273;  for mode=predcls, type=Mean Recall.
(above:0.1208) (across:0.0000) (against:0.0351) (along:0.1538) (and:0.0000) (at:0.1875) (attached to:0.1103) (behind:0.1615) (belonging to:0.0071) (between:0.0577) (carrying:0.1447) (covered in:0.2976) (covering:0.0857) (eating:0.1429) (flying in:0.0000) (for:0.0741) (from:0.0000) (growing on:0.0333) (hanging from:0.0037) (has:0.3032) (holding:0.1899) (in:0.3695) (in front of:0.0313) (laying on:0.0952) (looking at:0.0435) (lying on:0.0000) (made of:0.1429) (mounted on:0.0435) (near:0.0770) (of:0.3743) (on:0.3304) (on back of:0.0909) (over:0.0244) (painted on:0.0000) (parked on:0.3732) (part of:0.0000) (playing:0.0000) (riding:0.2857) (says:0.0000) (sitting on:0.2637) (standing on:0.0228) (to:0.1944) (under:0.0587) (using:0.2500) (walking in:0.0962) (walking on:0.1512) (watching:0.1275) (wearing:0.5627) (wears:0.0737) (with:0.1727) 
SGG eval:   A @ 20: 0.3372;   A @ 50: 0.3396;   A @ 100: 0.3396;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2023-02-24 03:53:25,262 maskrcnn_benchmark INFO: Validation Result: 0.3063
2023-02-24 03:53:25,263 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1
2023-02-24 03:55:02,797 maskrcnn_benchmark INFO: eta: 17:48:24  iter: 6200  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4671 (1.8966)  data: 0.0041 (1.4188)  lr: 0.001000  max mem: 3144
2023-02-24 03:56:38,017 maskrcnn_benchmark INFO: eta: 17:17:14  iter: 6400  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4573 (1.8522)  data: 0.0041 (1.3746)  lr: 0.001000  max mem: 3144
2023-02-24 03:58:13,912 maskrcnn_benchmark INFO: eta: 16:47:54  iter: 6600  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4542 (1.8106)  data: 0.0042 (1.3330)  lr: 0.001000  max mem: 3144
2023-02-24 03:59:49,957 maskrcnn_benchmark INFO: eta: 16:20:13  iter: 6800  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4775 (1.7715)  data: 0.0042 (1.2940)  lr: 0.001000  max mem: 3144
2023-02-24 04:01:26,668 maskrcnn_benchmark INFO: eta: 15:54:04  iter: 7000  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4717 (1.7347)  data: 0.0042 (1.2571)  lr: 0.001000  max mem: 3144
2023-02-24 04:03:02,272 maskrcnn_benchmark INFO: eta: 15:29:12  iter: 7200  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4589 (1.6998)  data: 0.0042 (1.2223)  lr: 0.001000  max mem: 3144
2023-02-24 04:04:37,953 maskrcnn_benchmark INFO: eta: 15:05:36  iter: 7400  loss: 189.6260 (nan)  loss_rel: 185.5974 (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4373 (1.6668)  data: 0.0041 (1.1894)  lr: 0.001000  max mem: 3144
2023-02-24 04:06:13,858 maskrcnn_benchmark INFO: eta: 14:43:10  iter: 7600  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4548 (1.6355)  data: 0.0041 (1.1582)  lr: 0.001000  max mem: 3144
2023-02-24 04:07:49,324 maskrcnn_benchmark INFO: eta: 14:21:47  iter: 7800  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4590 (1.6058)  data: 0.0042 (1.1286)  lr: 0.001000  max mem: 3144
2023-02-24 04:09:24,051 maskrcnn_benchmark INFO: ---Total norm 0.00000 clip coef 5000000.00000-----------------
2023-02-24 04:09:24,052 maskrcnn_benchmark INFO: -------------------------------
2023-02-24 04:09:24,053 maskrcnn_benchmark INFO: eta: 14:01:20  iter: 8000  loss: nan (nan)  loss_rel: nan (nan)  loss_refine_obj: 4.0286 (4.0286)  time: 0.4686 (1.5775)  data: 0.0042 (1.1005)  lr: 0.001000  max mem: 3144
2023-02-24 04:09:24,058 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./output/relation_baseline/model_0008000.pth
2023-02-24 04:09:55,224 maskrcnn_benchmark INFO: Start validating
2023-02-24 04:09:55,470 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2023-02-24 10:27:52,708 maskrcnn_benchmark INFO: Using 1 GPUs
2023-02-24 10:27:52,708 maskrcnn_benchmark INFO: Namespace(config_file='', local_rank=0, skip_test=False, opts=[], distributed=False)
2023-02-24 10:27:52,708 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2023-02-24 10:27:54,777 maskrcnn_benchmark INFO: 
PyTorch version: 1.13.0+cu117
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Fedora Linux 37 (KDE Plasma) (x86_64)
GCC version: (GCC) 12.2.1 20221121 (Red Hat 12.2.1-4)
Clang version: 15.0.7 (Fedora 15.0.7-1.fc37)
CMake version: version 3.26.0-rc3
Libc version: glibc-2.36

Python version: 3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-6.1.11-200.fc37.x86_64-x86_64-with-glibc2.36
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: 
GPU 0: NVIDIA GeForce RTX 3090
GPU 1: NVIDIA GeForce RTX 3090
GPU 2: NVIDIA GeForce RTX 3090

Nvidia driver version: 525.89.02
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] numpy==1.23.5
[pip3] torch==1.13.0
[pip3] torch-scatter==2.1.0
[pip3] torchaudio==0.13.0
[pip3] torchvision==0.14.0
[conda] Could not collect
        Pillow (9.3.0)
2023-02-24 10:27:54,777 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml
2023-02-24 10:27:54,777 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  #WEIGHT: "catalog://ImageNetPretrained/20171220/X-101-32x8d"
  PRETRAINED_DETECTOR_CKPT: "/users/students/r0879687/amager/vg/pretrained-detector/pretrained_faster_rcnn/model_final.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #################### Select Relationship Model ####################
    PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    #PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048
    ############### Parameters for Energy Model ##############
    EBM:
      OBJ_EMBED_DIM: 512
      REL_EMBED_DIM: 512
      OBJ_LABEL_EMBED_DIM: 512
      REL_LABEL_EMBED_DIM: 512
      POOLING_DIM: 512
DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5

2023-02-24 10:27:54,779 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  NUM_OBJ_CLASSES: -1
  NUM_REL_CLASSES: -1
  TEST: ('VG_stanford_filtered_with_attribute_test',)
  TRAIN: ('VG_stanford_filtered_with_attribute_train',)
  VAL: ('VG_stanford_filtered_with_attribute_val',)
DTYPE: float32
ENERGY_MODEL:
  DATA_NOISE_VAR: 0.0001
  L2COEFF: 1
  LOSS: ContrastiveDivergence
  META_ARCHITECTURE: GraphEnergyModel
  TEMP: 1
  TRAINIG_MODE: joint
GLOVE_DIR: /users/students/r0879687/amager/vg/glove
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  FLIP_PROB_TRAIN: 0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  BASE_ONLY: True
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DEV_RUN: False
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PRETRAINED_DETECTOR_CKPT: /users/students/r0879687/amager/vg/pretrained-detector/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 201
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 151
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: none
      FUSION_TYPE: sum
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EBM:
      OBJ_EMBED_DIM: 512
      OBJ_LABEL_EMBED_DIM: 512
      POOLING_DIM: 512
      REL_EMBED_DIM: 512
      REL_LABEL_EMBED_DIM: 512
    EMBED_DIM: 200
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    LABEL_SMOOTHING_LOSS: False
    NUM_CLASSES: 51
    NUM_SAMPLE_PER_GT_REL: 4
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: ./output/relation_baseline
PATHS_CATALOG: /users/students/r0879687/Documents/Master_thesis/ebm/energy-based-scene-graph/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /users/students/r0879687/amager/vg/VG_100K
SAMPLER:
  GRAD_CLIP: 0.01
  ITERS: 10
  LR: 0.1
  NAME: SGLD
  VAR: 0.001
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 2000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 1
  MAX_ITER: 40000
  MOMENTUM: 0.9
  PRE_VAL: False
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 2000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
WANDB:
  MUTE: False
2023-02-24 10:27:54,779 maskrcnn_benchmark INFO: Saving config into: ./output/relation_baseline/config.yml
2023-02-24 10:27:54,817 maskrcnn_benchmark INFO: #################### prepare training ####################
2023-02-24 10:27:54,819 maskrcnn_benchmark.modeling.detector.generalized_rcnn INFO: #################### Building Backbone ####################
2023-02-24 10:27:56,233 maskrcnn_benchmark.modeling.detector.generalized_rcnn INFO: #################### Building RPN ####################
2023-02-24 10:27:56,247 maskrcnn_benchmark.modeling.detector.generalized_rcnn INFO: #################### Building ROI Heads ####################
2023-02-24 10:27:59,619 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-02-24 10:27:59,620 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2023-02-24 10:28:00,045 maskrcnn_benchmark.data.build INFO: Loading data statistics from: ./output/relation_baseline/VG_stanford_filtered_with_attribute_train_statistics.cache
2023-02-24 10:28:00,045 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-02-24 10:29:16,724 maskrcnn_benchmark INFO: #################### end model construction ####################
2023-02-24 10:29:35,491 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2023-02-24 10:29:35,492 maskrcnn_benchmark INFO: #################### end distributed ####################
2023-02-24 10:29:35,522 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from ./output/relation_baseline/model_0008000.pth
